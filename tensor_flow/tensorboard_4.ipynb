{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB93Ge748VQs"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "0sK8X2O9bTlz"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEYuO5NFwDK9"
      },
      "source": [
        "# Examining the TensorFlow Graph\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tensorboard/graphs\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorboard/blob/master/docs/graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/tensorboard/docs/graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56V5oun18ZdZ"
      },
      "source": [
        "## Overview\n",
        "\n",
        "TensorBoard’s **Graphs dashboard** is a powerful tool for examining your TensorFlow model. You can quickly view a conceptual graph of your model’s structure and ensure it matches your intended design. You can also view a op-level graph to understand how TensorFlow understands your program. Examining the op-level graph can give you insight as to how to change your model. For example, you can redesign your model if training is progressing slower than expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOSJ-4nteBYG"
      },
      "source": [
        "This tutorial presents a quick overview of how to generate graph diagnostic data and visualize it in TensorBoard’s Graphs dashboard. You’ll define and train a simple Keras Sequential model for the Fashion-MNIST dataset and learn how to log and examine your model graphs. You will also use a tracing API to generate graph data for functions created using the new `tf.function` annotation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNI1-dflrAo0"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6B95Hb6YVgPZ"
      },
      "outputs": [],
      "source": [
        "# %pip install tensorboard_plugin_profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_wqSAZExy6xV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-23 22:36:21.987313: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-23 22:36:21.994296: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748054182.002885  251841 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748054182.005282  251841 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1748054182.011634  251841 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1748054182.011645  251841 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1748054182.011646  251841 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1748054182.011646  251841 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-05-23 22:36:22.014227: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version:  2.19.0\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
        "    \"This notebook requires TensorFlow 2.0 or above.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qRZlYIEcJ56Z"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.19.0'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorboard\n",
        "tensorboard.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ao7fJW1Pyiza"
      },
      "outputs": [],
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e25E37vd1xEW"
      },
      "source": [
        "## Define a Keras model\n",
        "\n",
        "In this example, the classifier is a simple four-layer Sequential model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "skqORzvE3Egy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/oleg/Developer/GitHub/TensorFlow/TensorFlow/.venv/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "I0000 00:00:1748054183.369523  251841 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1067 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
          ]
        }
      ],
      "source": [
        "# Define the model.\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbjuoz9E3VC_"
      },
      "source": [
        "Download and prepare the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6TDmc41z3g38"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), _ = keras.datasets.fashion_mnist.load_data()\n",
        "train_images = train_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DV0xibO3bRC"
      },
      "source": [
        "## Train the model and log data\n",
        "\n",
        "Before training, define the [Keras TensorBoard callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard), specifying the log directory. By passing this callback to Model.fit(), you ensure that graph data is logged for visualization in TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TU_L_u9SqQdH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-23 22:36:23.905072: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.\n",
            "2025-05-23 22:36:23.905085: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1748054183.905104  251841 cupti_tracer.cc:1026] Profiler found 1 GPUs\n",
            "W0000 00:00:1748054183.914977  251841 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1\n",
            "2025-05-23 22:36:23.915077: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.\n",
            "I0000 00:00:1748054183.915130  251841 cupti_tracer.cc:1249] CUPTI activity buffer flushed\n"
          ]
        }
      ],
      "source": [
        "# Define the Keras TensorBoard callback.\n",
        "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "#tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "    log_dir=logdir,\n",
        "    histogram_freq=1,\n",
        "    write_graph=True,  # Ensure graph writing is enabled\n",
        "    profile_batch = '10,12',\n",
        "    update_freq='epoch'\n",
        ")\n",
        "\n",
        "\n",
        "# Train the model.\n",
        "# model.fit(\n",
        "#     train_images,\n",
        "#     train_labels, \n",
        "#     batch_size=64,\n",
        "#     epochs=5, \n",
        "#     callbacks=[tensorboard_callback])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1748054184.509208  251999 service.cc:152] XLA service 0x795de4016d00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1748054184.509224  251999 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
            "2025-05-23 22:36:24.519301: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1748054184.563229  251999 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m148/938\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4945 - loss: 1.4784"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1748054185.249909  251999 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "2025-05-23 22:36:25.283424: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.\n",
            "2025-05-23 22:36:25.283434: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.\n",
            "W0000 00:00:1748054185.290974  251841 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1\n",
            "2025-05-23 22:36:25.296469: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:68] Profiler session collecting data.\n",
            "I0000 00:00:1748054185.298132  251841 cupti_tracer.cc:1249] CUPTI activity buffer flushed\n",
            "I0000 00:00:1748054185.301608  251841 cupti_collector.cc:793]  GpuTracer has collected 120 callback api events and 110 activity events. \n",
            "I0000 00:00:1748054185.301751  251841 cupti_collector.cc:796]  GpuTracer max callback_events: 2097152, max activity events: 2097152\n",
            "2025-05-23 22:36:25.303235: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.\n",
            "2025-05-23 22:36:25.303511: I external/local_xla/xla/tsl/profiler/rpc/client/save_profile.cc:147] Collecting XSpace to repository: logs/fit/20250523-223623/train/plugins/profile/2025_05_23_22_36_25/oleg-G476.xplane.pb\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6749 - loss: 0.9544\n",
            "Epoch 2/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 0.8178 - loss: 0.5161\n",
            "Epoch 3/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 0.8327 - loss: 0.4707\n",
            "Epoch 4/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - accuracy: 0.8383 - loss: 0.4477\n",
            "Epoch 5/5\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 0.8402 - loss: 0.4391\n",
            "WARNING:tensorflow:Ignoring `profiler_outdir` passed to trace_export(). Please pass it to trace_on() instead.\n",
            "WARNING:tensorflow:Error while stopping profiler: Cannot export profiling results. No profiler is running.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-23 22:36:30.161365: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.\n",
            "2025-05-23 22:36:30.161375: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.\n",
            "W0000 00:00:1748054190.168614  251841 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1\n",
            "2025-05-23 22:36:30.170548: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:68] Profiler session collecting data.\n",
            "I0000 00:00:1748054190.172973  251841 cupti_tracer.cc:1249] CUPTI activity buffer flushed\n",
            "I0000 00:00:1748054190.177266  251841 cupti_collector.cc:793]  GpuTracer has collected 3 callback api events and 2 activity events. \n",
            "I0000 00:00:1748054190.177392  251841 cupti_collector.cc:796]  GpuTracer max callback_events: 2097152, max activity events: 2097152\n",
            "2025-05-23 22:36:30.178490: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.\n",
            "2025-05-23 22:36:30.178593: I external/local_xla/xla/tsl/profiler/rpc/client/save_profile.cc:147] Collecting XSpace to repository: logs/fit/20250523-223623/plugins/profile/2025_05_23_22_36_30/oleg-G476.xplane.pb\n"
          ]
        }
      ],
      "source": [
        "# If you're using custom functions with @tf.function, wrap the tracing properly:\n",
        "\n",
        "# Set up logging for custom functions\n",
        "writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "# Enable tracing\n",
        "#tf.summary.trace_on(graph=True, profiler=True)\n",
        "\n",
        "# Run your model/function\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels, \n",
        "    batch_size=64,\n",
        "    epochs=5, \n",
        "    callbacks=[tensorboard_callback])\n",
        "\n",
        "# Export the trace\n",
        "with writer.as_default():\n",
        "    tf.summary.trace_on(graph=True, profiler=True, profiler_outdir=logdir)\n",
        "    tf.summary.trace_export(\n",
        "        name=\"graph\",\n",
        "        step=0,\n",
        "        profiler_outdir=logdir\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRX5OIsi4TTV"
      },
      "source": [
        "## Op-level graph\n",
        "\n",
        "Start TensorBoard and wait a few seconds for the UI to load. Select the Graphs dashboard by tapping “Graphs” at the top. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PFgFjlPEqXb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6011 (pid 252536), started 0:00:11 ago. (Use '!kill 252536' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-ea986cbeb801091b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-ea986cbeb801091b\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6011;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGlOqRp54ufD"
      },
      "source": [
        "By default, TensorBoard displays the **op-level graph**. (On the left, you can see the “Default” tag selected.)  Note that the graph is inverted; data flows from bottom to top, so it’s upside down compared to the code. However, you can see that the graph closely matches the Keras model definition, with extra edges to other computation nodes.\n",
        "\n",
        "Graphs are often very large, so you can manipulate the graph visualization:\n",
        "\n",
        "* Scroll to **zoom** in and out\n",
        "* Drag to **pan**\n",
        "* Double clicking toggles **node expansion** (a node can be a container for other nodes)\n",
        "\n",
        "You can also see metadata by clicking on a node. This allows you to see inputs, outputs, shapes and other details.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-2yw5qd7OpK"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/graphs_computation.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDRynpVw53SJ"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/graphs_computation_detail.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj9FSPdz6SO2"
      },
      "source": [
        "## Conceptual graph\n",
        "\n",
        "In addition to the execution graph, TensorBoard also displays a **conceptual graph**. This is a view of just the Keras model. This may be useful if you’re reusing a saved model and you want to examine or validate its structure.\n",
        "\n",
        "To see the conceptual graph, select the “keras” tag. For this example, you’ll see a collapsed **Sequential** node. Double-click the node to see the model’s structure:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw9rbEcE6eZB"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/graphs_tag_selection.png?raw=1\"/> --> <br/>\n",
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/graphs_conceptual.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVuaKBifu-qF"
      },
      "source": [
        "## Graphs of tf.functions\n",
        "\n",
        "The examples so far have described graphs of Keras models, where the graphs have been created by defining Keras layers and calling Model.fit().\n",
        "\n",
        "You may encounter a situation where you need to use the `tf.function` annotation to [\"autograph\"](https://www.tensorflow.org/guide/function), i.e., transform, a Python computation function into a high-performance TensorFlow graph. For these situations, you use **TensorFlow Summary Trace API** to log autographed functions for visualization in TensorBoard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIuhJnQ8w-dT"
      },
      "source": [
        "To use the Summary Trace API:\n",
        "\n",
        "*   Define and annotate a function with `tf.function`\n",
        "*   Use `tf.summary.trace_on()` immediately before your function call site.\n",
        "*    Add profile information (memory, CPU time) to graph by passing `profiler=True`\n",
        "*   With a Summary file writer, call `tf.summary.trace_export()` to save the log data\n",
        "\n",
        "You can then use TensorBoard to see how your function behaves.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "woI67Stgv_uY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No `profiler_outdir` passed to trace_on(). Profiler won't be enabled.\n",
            "WARNING:tensorflow:Ignoring `profiler_outdir` passed to trace_export(). Please pass it to trace_on() instead.\n"
          ]
        },
        {
          "ename": "UnavailableError",
          "evalue": "Cannot export profiling results. No profiler is running.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mUnavailableError\u001b[39m                          Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m z = my_func(x, y)\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m writer.as_default():\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m   \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmy_func_trace\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m      \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m      \u001b[49m\u001b[43mprofiler_outdir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogdir\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/GitHub/TensorFlow/TensorFlow/.venv/lib/python3.12/site-packages/tensorflow/python/ops/summary_ops_v2.py:1438\u001b[39m, in \u001b[36mtrace_export\u001b[39m\u001b[34m(name, step, profiler_outdir)\u001b[39m\n\u001b[32m   1433\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m profiler_outdir:\n\u001b[32m   1434\u001b[39m     logging.warn(\n\u001b[32m   1435\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIgnoring `profiler_outdir` passed to trace_export(). Please pass it\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1436\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m to trace_on() instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1437\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1438\u001b[39m   \u001b[43m_profiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1440\u001b[39m trace_off()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/GitHub/TensorFlow/TensorFlow/.venv/lib/python3.12/site-packages/tensorflow/python/profiler/profiler_v2.py:144\u001b[39m, in \u001b[36mstop\u001b[39m\u001b[34m(save)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _profiler_lock:\n\u001b[32m    143\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m _profiler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m errors.UnavailableError(\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    146\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mCannot export profiling results. No profiler is running.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    147\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m save:\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[31mUnavailableError\u001b[39m: Cannot export profiling results. No profiler is running."
          ]
        }
      ],
      "source": [
        "# The function to be traced.\n",
        "@tf.function\n",
        "def my_func(x, y):\n",
        "  # A simple hand-rolled layer.\n",
        "  return tf.nn.relu(tf.matmul(x, y))\n",
        "\n",
        "# Set up logging.\n",
        "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "logdir = 'logs/func/%s' % stamp\n",
        "writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "# Sample data for your function.\n",
        "x = tf.random.uniform((3, 3))\n",
        "y = tf.random.uniform((3, 3))\n",
        "\n",
        "# Bracket the function call with\n",
        "# tf.summary.trace_on() and tf.summary.trace_export().\n",
        "tf.summary.trace_on(graph=True, profiler=True)\n",
        "# Call only one tf.function when tracing.\n",
        "z = my_func(x, y)\n",
        "with writer.as_default():\n",
        "  tf.summary.trace_export(\n",
        "      name=\"my_func_trace\",\n",
        "      step=0,\n",
        "      profiler_outdir=logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCArnWzP0VuZ"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/func"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDl1PBFQ64xi"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/tensorboard/blob/master/docs/images/graphs_autograph.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pLRaf3q6Nku"
      },
      "source": [
        "You can now see the structure of your function as understood by TensorBoard. Click on the \"Profile\" radiobutton to see CPU and memory statistics."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SB93Ge748VQs"
      ],
      "name": "graphs.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
